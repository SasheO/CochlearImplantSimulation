{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53a52c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Look into outputs. \n",
    "\n",
    "Phonemes labels are at the end of each line. \n",
    "\n",
    "Get average length of phoneme. \n",
    "\n",
    "Get the mean feature, the average, everything from post two weeks. \n",
    "\n",
    "Change kevin's code in your directory to write outputs to output dir.\n",
    "\n",
    "Find out which files were affected in Kevin's dataset. Replace them.\n",
    "'''\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1a43d",
   "metadata": {},
   "source": [
    "# Getting Average Length of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "140b35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if file has been opened\n",
    "def is_timit_txt_file_processed(filename): # checks if file is shorter than 1000 kb\n",
    "    return os.path.getsize(filename) > 1000\n",
    "\n",
    "def is_timit_txt_file_processe2(filename): # slower because it opens files and checks if it is only one line (the sentence spoken as obseved in timit dataset) or multiple. use as confirmation\n",
    "    f = open(filename, \"r\")\n",
    "    lines = f.readlines()\n",
    "    return not len(lines)==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d212db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Look into outputs. \n",
    "Open each file and read line by line. get number of lines for each file\n",
    "add them into all files\n",
    "find average for each phoneme\n",
    "find weighted average for all phonemes\n",
    "\n",
    "NOTES:\n",
    "each line is 131 long, phoneme inclusive\n",
    "'''\n",
    "def get_phonemes_features_lengths_single_file(filename):\n",
    "    '''\n",
    "    gets the number of feature lines corresponding to each phoneme in a file\n",
    "    \n",
    "    input:\n",
    "        filename (str): the name of the file\n",
    "    \n",
    "    output:\n",
    "        phonemes_to_lengths (dict): a map of the phoneme to a list of the number of feature lines corresponding to each occurence of the phoneme. For example, if the aa phoneme occurs twice in the input file and the first time is 15 line and the second is 20 lines long, the output will include 'aa': [15,20]\n",
    "    '''\n",
    "    previous_phoneme = \"\"\n",
    "    phonemes_to_lengths = {}\n",
    "    f = open(filename, \"r\")\n",
    "    lines = f.readlines()\n",
    "    for line in lines: \n",
    "        phoneme = line.split()[-1]\n",
    "        if phoneme in phonemes_to_lengths: # repeat occurence of phoneme\n",
    "            if phoneme == previous_phoneme: # still same phoneme, increment count\n",
    "                phonemes_to_lengths[phoneme][-1] += 1\n",
    "            else: # different phoneme, start counter for phoneme\n",
    "                phonemes_to_lengths[phoneme].append(1)\n",
    "        else: # first occurence of phoneme\n",
    "            phonemes_to_lengths[phoneme] = [1]\n",
    "        previous_phoneme = phoneme\n",
    "    return phonemes_to_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506bcc9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h#': [44, 62], 'ax-h': [20, 10], 's': [53, 52], 'ey': [51, 43], 'l': [7, 26], 'v': [17, 23], 'ow': [56, 79], 'q': [10, 25], 'm': [32, 28, 37], 'hv': [40, 25], 'ae': [55], 'ax': [25], 'bcl': [35, 22], 'b': [12, 18], 'n': [15, 36, 34, 17, 22, 34], 'ih': [46, 36, 26], 'axr': [26], 'tcl': [37, 18], 't': [23, 21], 'iy': [50], 'dh': [38, 11], 'w': [35], 'ah': [30], 'ix': [22, 15], 'ay': [48], 'kcl': [24, 51], 'k': [37], 'aa': [60], 'eh': [86]}\n"
     ]
    }
   ],
   "source": [
    "filename = \"Y:/personal/ojuba.mezisashe/timit_dp_test_extract_features/TRAIN/DR1/FCJF0/SI648.txt\"\n",
    "print(get_phonemes_features_lengths_single_file(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0de1c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get list of all files.\n",
    "iterate through all files, use get_phonemes_features_lengths_single_file(filename)\n",
    "integrate outputs into single output\n",
    "get average per phoneme and total weighted average\n",
    "'''\n",
    "\n",
    "# get list of all files\n",
    "files_searching = [] # list of all files that will be used in getting weighted average\n",
    "directory_train_or_dev = \"Y:\\\\personal\\\\ojuba.mezisashe\\\\timit_dp_test_extract_features\\\\TRAIN\" # should be of depth = (dev, test, or train) in timit dataset\n",
    "for current_directory,subfolders,files in list(os.walk(directory_train_or_dev))[2:]:\n",
    "    for file in files:\n",
    "        file = current_directory + \"\\\\\" + file\n",
    "        if file.lower().endswith(\".txt\"):\n",
    "            if is_timit_txt_file_processed(file): \n",
    "                files_searching.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79950f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all files, use get_phonemes_features_lengths_single_file(filename)\n",
    "# integrate outputs into single output\n",
    "phonemes_to_lengths = {}\n",
    "for file in files_searching:\n",
    "    phonemes_to_lengths_single_file = get_phonemes_features_lengths_single_file(file)\n",
    "    for phoneme in phonemes_to_lengths_single_file:\n",
    "        if phoneme in phonemes_to_lengths:\n",
    "            phonemes_to_lengths[phoneme].extend(phonemes_to_lengths_single_file[phoneme])\n",
    "        else:\n",
    "            phonemes_to_lengths[phoneme] = phonemes_to_lengths_single_file[phoneme]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9182da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average per phoneme and total weighted average\n",
    "# total is calculated without 'h#' phoneme\n",
    "average_phoneme_lengths = {} # get average per phoneme and total weighted average in 'total' key\n",
    "num_phonemes_total = 0\n",
    "for phoneme in phonemes_to_lengths:\n",
    "    average_phoneme_lengths[phoneme] = sum(phonemes_to_lengths[phoneme])/len(phonemes_to_lengths[phoneme])\n",
    "    num_phonemes_total += len(phonemes_to_lengths[phoneme])\n",
    "\n",
    "average_phoneme_lengths['total'] = 0\n",
    "for phoneme in phonemes_to_lengths:\n",
    "    if phoneme == \"h#\":\n",
    "        pass\n",
    "    else:\n",
    "        average_phoneme_lengths['total'] += average_phoneme_lengths[phoneme] * (len(phonemes_to_lengths[phoneme])/num_phonemes_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a64b07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h#': 91.61307901907357,\n",
       " 'q': 31.835365853658537,\n",
       " 'iy': 45.330232558139535,\n",
       " 'v': 30.303030303030305,\n",
       " 'ih': 38.78341013824885,\n",
       " 'n': 27.721854304635762,\n",
       " 'eh': 45.829268292682926,\n",
       " 'ix': 23.439560439560438,\n",
       " 'f': 53.99173553719008,\n",
       " 'sh': 58.641975308641975,\n",
       " 'tcl': 27.133587786259543,\n",
       " 't': 24.478021978021978,\n",
       " 'uh': 35.18181818181818,\n",
       " 'kcl': 30.07,\n",
       " 'k': 26.00561797752809,\n",
       " 'w': 26.726315789473684,\n",
       " 'ah': 43.03603603603604,\n",
       " 's': 58.463667820069205,\n",
       " 'pcl': 34.18181818181818,\n",
       " 'ow': 64.66265060240964,\n",
       " 'dcl': 25.246376811594203,\n",
       " 'd': 12.285714285714286,\n",
       " 'hh': 32.41463414634146,\n",
       " 'ae': 71.80714285714286,\n",
       " 'ch': 44.075,\n",
       " 'epi': 19.70212765957447,\n",
       " 'axr': 37.883495145631066,\n",
       " 'ao': 56.529411764705884,\n",
       " 'r': 27.349282296650717,\n",
       " 'bcl': 31.606060606060606,\n",
       " 'b': 10.18421052631579,\n",
       " 'aa': 64.97142857142858,\n",
       " 'ax': 22.910179640718564,\n",
       " 'em': 46.44444444444444,\n",
       " 'ng': 29.982142857142858,\n",
       " 'gcl': 26.723076923076924,\n",
       " 'g': 14.307692307692308,\n",
       " 'hv': 33.86486486486486,\n",
       " 'm': 33.105555555555554,\n",
       " 'ay': 79.94897959183673,\n",
       " 'th': 50.625,\n",
       " 'ax-h': 17.391304347826086,\n",
       " 'ey': 60.981308411214954,\n",
       " 'l': 29.56387665198238,\n",
       " 'dh': 17.346456692913385,\n",
       " 'p': 21.84090909090909,\n",
       " 'dx': 14.037037037037036,\n",
       " 'aw': 74.13888888888889,\n",
       " 'er': 60.822784810126585,\n",
       " 'nx': 13.0,\n",
       " 'z': 42.723270440251575,\n",
       " 'jh': 31.369565217391305,\n",
       " 'el': 43.05769230769231,\n",
       " 'uw': 57.0,\n",
       " 'ux': 54.30769230769231,\n",
       " 'oy': 79.95238095238095,\n",
       " 'y': 30.462962962962962,\n",
       " 'en': 39.94285714285714,\n",
       " 'pau': 87.34426229508196,\n",
       " 'zh': 42.285714285714285,\n",
       " '0.5': 1.0,\n",
       " 'total': 34.64579479151841}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_phoneme_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "944c65d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(average_phoneme_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "434dd2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "manner_of_articulation_map = {\"vowels\":{\"iy\",\"ih\", 'eh', 'ae', 'aa', 'ah', 'ao', 'uh', 'uw', 'ux', 'ax', 'ax-h', 'ix'},\n",
    "                             \"dipthongs\":{'ey', 'aw', 'ay', 'oy', 'ow'},\n",
    "                             \"semi-vowels\": {'l', 'el', 'r', 'w', 'y', 'er', 'axr'},\n",
    "                             \"stops\": {'b', 'd', 'g', 'p', 't', 'k', 'jh', 'ch'},\n",
    "                             \"fricatives\": {'s', 'sh', 'z', 'zh', 'f', 'th', 'v', 'dh', 'hh', 'hv'},\n",
    "                             \"nasals\": {'m', 'em', 'n', 'nx', 'ng', 'eng', 'en'},\n",
    "                             \"silence\": {'dx', 'bcl', 'dcl', 'gcl', 'pcl', 'tcl', 'kcl', 'h', 'pau', 'epi', 'q'},\n",
    "                             \"h#\": {\"h#\"}} # from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4100697  3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8df48f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(x) for x,y in manner_of_articulation_map.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241cdc5d",
   "metadata": {},
   "source": [
    "# UMAP visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: review an edit this so it works on the new data\n",
    "\n",
    "\n",
    "# singular feature is df.iloc[:,:5]\n",
    "'''\n",
    "unroll the data one row after another\n",
    "\n",
    "get colour names into a separate array based on phoneme\n",
    "'''\n",
    "\n",
    "\n",
    "weighted_average_phoneme_length = int(average_phoneme_lengths['total']) # around 34.64579479151841\n",
    "\n",
    "features_rolled_out = []\n",
    "phoneme_to_number = {}\n",
    "phonemes_from = [] # this will put the phonemes here which will be used to colour code the data\n",
    "\n",
    "current = 0\n",
    "_break = False\n",
    "for filename in files_searching:\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    df.fillna(value=0, inplace=True)\n",
    "    df = df.reindex(columns = df.columns.tolist() + list(range(df.shape[1]+1, weighted_average_phoneme_length+1)))\n",
    "    df = df.iloc[:,:num_features_using]\n",
    "\n",
    "    if df.shape[1] < num_features_using:\n",
    "        df = df.reindex(columns = df.columns.tolist() + list(range(df.shape[1]+1, weighted_average_phoneme_length+1)))\n",
    "\n",
    "    features_rolled_out.append(df.iloc[:,:100].transpose().values.flatten())\n",
    "    phoneme = directory.rsplit('/', 1)[-1]\n",
    "    if phoneme in phoneme_to_number:\n",
    "        pass\n",
    "    else:\n",
    "        phoneme_to_number[phoneme] = len(phoneme_to_number)+1\n",
    "\n",
    "    phonemes_from.append(phoneme_to_number[phoneme])\n",
    "        current += 1\n",
    "        \n",
    "#         if current == 100:\n",
    "#             _break = True\n",
    "#             break\n",
    "#     if _break:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09294941",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_rolled_out = np.array(features_rolled_out, dtype=float)\n",
    "features_rolled_out = np.nan_to_num(features_rolled_out, copy=True, posinf=0, neginf=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy pasted most of this code from mnist example\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embedding = reducer.fit_transform(features_rolled_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9655cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if issues, may be due to nan values. think how to deal with sparse data? maybe cut off at some point.\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "colors = phonemes_from\n",
    "\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=colors, cmap=\"Spectral\", s=10)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "plt.title(\"Phonemes\", fontsize=18)\n",
    "# plt.colorbar().ax.ticks=np.linspace(0,max())\n",
    "plt.colorbar().ax.tick_params(labelsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca83b94",
   "metadata": {},
   "source": [
    "# Zmuv normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2c1a122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlook over data.\\nuse matlab to understand how the data opens up\\n\\n\\nGet mean and standard deviation of each phoneme class.\\n\\t5. Perhaps visualize/plot the average phoneme for each phoneme class.\\n\\t6. For a phoneme, normalize by class: subtract from the mean and divide by standard deviation. And time align.\\n\\t7. Visualize the normalized features.\\nLook at the difference in pattern between normalized and un-normalized features.\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mean feature, the average, everything from post two weeks. \n",
    "'''\n",
    "look over data.\n",
    "use matlab to understand how the data opens up\n",
    "\n",
    "\n",
    "Get mean and standard deviation of each phoneme class.\n",
    "\t5. Perhaps visualize/plot the average phoneme for each phoneme class.\n",
    "\t6. For a phoneme, normalize by class: subtract from the mean and divide by standard deviation. And time align.\n",
    "\t7. Visualize the normalized features.\n",
    "Look at the difference in pattern between normalized and un-normalized features.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get average by phoneme. \n",
    "open files and read phonemes into matrix. maybe by phoneme?\n",
    "get average and mean of phoneme class\n",
    "save average and mean of phoneme class (maybe to dictionary)\n",
    "visualize average for each phoneme class\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25096179",
   "metadata": {},
   "source": [
    "## Test Zmuv normalization and visualization for one phoneme class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2fcb0e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme = \"aa\"\n",
    "average_phoneme_class_length = int(average_phoneme_lengths[phoneme])\n",
    "\n",
    "for file in files_searching:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5bfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
